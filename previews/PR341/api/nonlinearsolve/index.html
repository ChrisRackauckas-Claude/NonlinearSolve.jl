<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>NonlinearSolve.jl Native Solvers · NonlinearSolve.jl</title><meta name="title" content="NonlinearSolve.jl Native Solvers · NonlinearSolve.jl"/><meta property="og:title" content="NonlinearSolve.jl Native Solvers · NonlinearSolve.jl"/><meta property="twitter:title" content="NonlinearSolve.jl Native Solvers · NonlinearSolve.jl"/><meta name="description" content="Documentation for NonlinearSolve.jl."/><meta property="og:description" content="Documentation for NonlinearSolve.jl."/><meta property="twitter:description" content="Documentation for NonlinearSolve.jl."/><meta property="og:url" content="https://docs.sciml.ai/NonlinearSolve/stable/api/nonlinearsolve/"/><meta property="twitter:url" content="https://docs.sciml.ai/NonlinearSolve/stable/api/nonlinearsolve/"/><link rel="canonical" href="https://docs.sciml.ai/NonlinearSolve/stable/api/nonlinearsolve/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NonlinearSolve.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NonlinearSolve.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">NonlinearSolve.jl: High-Performance Unified Nonlinear Solvers</a></li><li><a class="tocitem" href="../../tutorials/getting_started/">Getting Started with Nonlinear Rootfinding in Julia</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/code_optimization/">Code Optimization for Small Nonlinear Systems in Julia</a></li><li><a class="tocitem" href="../../tutorials/large_systems/">Efficiently Solving Large Sparse Ill-Conditioned Nonlinear Systems in Julia</a></li><li><a class="tocitem" href="../../tutorials/modelingtoolkit/">Symbolic Nonlinear System Definition and Acceleration via ModelingToolkit</a></li><li><a class="tocitem" href="../../tutorials/small_compile/">Faster Startup and and Static Compilation</a></li><li><a class="tocitem" href="../../tutorials/iterator_interface/">Nonlinear Solver Iterator Interface</a></li><li><a class="tocitem" href="../../tutorials/optimizing_parameterized_ode/">Optimizing a Parameterized ODE</a></li></ul></li><li><span class="tocitem">Basics</span><ul><li><a class="tocitem" href="../../basics/NonlinearProblem/">Nonlinear Problems</a></li><li><a class="tocitem" href="../../basics/NonlinearFunctions/">NonlinearFunctions and Jacobian Types</a></li><li><a class="tocitem" href="../../basics/solve/">Common Solver Options (Solve Keyword Arguments)</a></li><li><a class="tocitem" href="../../basics/NonlinearSolution/">Nonlinear Solutions</a></li><li><a class="tocitem" href="../../basics/TerminationCondition/">Termination Conditions</a></li><li><a class="tocitem" href="../../basics/Logging/">Logging the Solve Process</a></li><li><a class="tocitem" href="../../basics/SparsityDetection/">(Semi-)Automatic Sparsity Detection</a></li><li><a class="tocitem" href="../../basics/FAQ/">Frequently Asked Questions</a></li></ul></li><li><span class="tocitem">Solver Summaries and Recommendations</span><ul><li><a class="tocitem" href="../../solvers/NonlinearSystemSolvers/">Nonlinear System Solvers</a></li><li><a class="tocitem" href="../../solvers/BracketingSolvers/">Interval Rootfinding Methods (Bracketing Solvers)</a></li><li><a class="tocitem" href="../../solvers/SteadyStateSolvers/">Steady State Solvers</a></li><li><a class="tocitem" href="../../solvers/NonlinearLeastSquaresSolvers/">Nonlinear Least Squares Solvers</a></li><li><a class="tocitem" href="../../solvers/FixedPointSolvers/">Fixed Point Solvers</a></li><li><a class="tocitem" href="../../solvers/LineSearch/">Line Search</a></li></ul></li><li><span class="tocitem">Detailed Solver APIs</span><ul><li class="is-active"><a class="tocitem" href>NonlinearSolve.jl Native Solvers</a><ul class="internal"><li><a class="tocitem" href="#Nonlinear-Solvers"><span>Nonlinear Solvers</span></a></li><li><a class="tocitem" href="#Nonlinear-Least-Squares-Solvers"><span>Nonlinear Least Squares Solvers</span></a></li><li><a class="tocitem" href="#Both-Nonlinear-and-Nonlinear-Least-Squares-Solvers"><span>Both Nonlinear &amp; Nonlinear Least Squares Solvers</span></a></li><li><a class="tocitem" href="#Polyalgorithms"><span>Polyalgorithms</span></a></li><li><a class="tocitem" href="#Radius-Update-Schemes-for-Trust-Region-(RadiusUpdateSchemes)"><span>Radius Update Schemes for Trust Region (RadiusUpdateSchemes)</span></a></li></ul></li><li><a class="tocitem" href="../simplenonlinearsolve/">SimpleNonlinearSolve.jl</a></li><li><a class="tocitem" href="../minpack/">MINPACK.jl</a></li><li><a class="tocitem" href="../nlsolve/">NLsolve.jl</a></li><li><a class="tocitem" href="../sundials/">Sundials.jl</a></li><li><a class="tocitem" href="../steadystatediffeq/">SteadyStateDiffEq.jl</a></li><li><a class="tocitem" href="../leastsquaresoptim/">LeastSquaresOptim.jl</a></li><li><a class="tocitem" href="../fastlevenbergmarquardt/">FastLevenbergMarquardt.jl</a></li><li><a class="tocitem" href="../speedmapping/">SpeedMapping.jl</a></li><li><a class="tocitem" href="../fixedpointacceleration/">FixedPointAcceleration.jl</a></li><li><a class="tocitem" href="../siamfanlequations/">SIAMFANLEquations.jl</a></li></ul></li><li><a class="tocitem" href="../../release_notes/">Release Notes</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Detailed Solver APIs</a></li><li class="is-active"><a href>NonlinearSolve.jl Native Solvers</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>NonlinearSolve.jl Native Solvers</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/NonlinearSolve.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/NonlinearSolve.jl/blob/master/docs/src/api/nonlinearsolve.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="NonlinearSolve.jl-Native-Solvers"><a class="docs-heading-anchor" href="#NonlinearSolve.jl-Native-Solvers">NonlinearSolve.jl Native Solvers</a><a id="NonlinearSolve.jl-Native-Solvers-1"></a><a class="docs-heading-anchor-permalink" href="#NonlinearSolve.jl-Native-Solvers" title="Permalink"></a></h1><p>These are the native solvers of NonlinearSolve.jl.</p><h2 id="Nonlinear-Solvers"><a class="docs-heading-anchor" href="#Nonlinear-Solvers">Nonlinear Solvers</a><a id="Nonlinear-Solvers-1"></a><a class="docs-heading-anchor-permalink" href="#Nonlinear-Solvers" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.NewtonRaphson" href="#NonlinearSolve.NewtonRaphson"><code>NonlinearSolve.NewtonRaphson</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NewtonRaphson(; concrete_jac = nothing, linsolve = nothing, linesearch = nothing,
    precs = DEFAULT_PRECS, adkwargs...)</code></pre><p>An advanced NewtonRaphson implementation with support for efficient handling of sparse matrices via colored automatic differentiation and preconditioned linear solvers. Designed for large-scale and numerically-difficult nonlinear systems.</p><p><strong>Keyword Arguments</strong></p><ul><li><code>autodiff</code>: determines the backend used for the Jacobian. Note that this argument is ignored if an analytical Jacobian is passed, as that will be used instead. Defaults to <code>nothing</code> which means that a default is selected according to the problem specification! Valid choices are types from ADTypes.jl.</li><li><code>concrete_jac</code>: whether to build a concrete Jacobian. If a Krylov-subspace method is used, then the Jacobian will not be constructed and instead direct Jacobian-vector products <code>J*v</code> are computed using forward-mode automatic differentiation or finite differencing tricks (without ever constructing the Jacobian). However, if the Jacobian is still needed, for example for a preconditioner, <code>concrete_jac = true</code> can be passed in order to force the construction of the Jacobian.</li><li><code>linsolve</code>: the <a href="https://github.com/SciML/LinearSolve.jl">LinearSolve.jl</a> used for the linear solves within the Newton method. Defaults to <code>nothing</code>, which means it uses the LinearSolve.jl default algorithm choice. For more information on available algorithm choices, see the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>precs</code>: the choice of preconditioners for the linear solver. Defaults to using no preconditioners. For more information on specifying preconditioners for LinearSolve algorithms, consult the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>linesearch</code>: the line search algorithm to use. Defaults to <a href="../../solvers/LineSearch/#NonlinearSolve.LineSearch"><code>LineSearch()</code></a>, which means that no line search is performed. Algorithms from <code>LineSearches.jl</code> can be used here directly, and they will be converted to the correct <code>LineSearch</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/raphson.jl#L1-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.PseudoTransient" href="#NonlinearSolve.PseudoTransient"><code>NonlinearSolve.PseudoTransient</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PseudoTransient(; concrete_jac = nothing, linsolve = nothing,
    precs = DEFAULT_PRECS, alpha_initial = 1e-3, adkwargs...)</code></pre><p>An implementation of PseudoTransient method that is used to solve steady state problems in an accelerated manner. It uses an adaptive time-stepping to integrate an initial value of nonlinear problem until sufficient accuracy in the desired steady-state is achieved to switch over to Newton&#39;s method and gain a rapid convergence. This implementation specifically uses &quot;switched evolution relaxation&quot; SER method. For detail information about the time-stepping and algorithm, please see the paper: <a href="https://doi.org/10.1137/S106482750241044X">Coffey, Todd S. and Kelley, C. T. and Keyes, David E. (2003), Pseudotransient Continuation and Differential-Algebraic Equations, SIAM Journal on Scientific Computing,25, 553-569.</a></p><p><strong>Keyword Arguments</strong></p><ul><li><code>autodiff</code>: determines the backend used for the Jacobian. Note that this argument is ignored if an analytical Jacobian is passed, as that will be used instead. Defaults to <code>nothing</code> which means that a default is selected according to the problem specification! Valid choices are types from ADTypes.jl.</li><li><code>concrete_jac</code>: whether to build a concrete Jacobian. If a Krylov-subspace method is used, then the Jacobian will not be constructed and instead direct Jacobian-vector products <code>J*v</code> are computed using forward-mode automatic differentiation or finite differencing tricks (without ever constructing the Jacobian). However, if the Jacobian is still needed, for example for a preconditioner, <code>concrete_jac = true</code> can be passed in order to force the construction of the Jacobian.</li><li><code>linsolve</code>: the <a href="https://github.com/SciML/LinearSolve.jl">LinearSolve.jl</a> used for the linear solves within the Newton method. Defaults to <code>nothing</code>, which means it uses the LinearSolve.jl default algorithm choice. For more information on available algorithm choices, see the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>precs</code>: the choice of preconditioners for the linear solver. Defaults to using no preconditioners. For more information on specifying preconditioners for LinearSolve algorithms, consult the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>alpha_initial</code> : the initial pseudo time step. it defaults to 1e-3. If it is small, you are going to need more iterations to converge but it can be more stable.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/pseudotransient.jl#L1-L36">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.DFSane" href="#NonlinearSolve.DFSane"><code>NonlinearSolve.DFSane</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DFSane(; σ_min::Real = 1e-10, σ_max::Real = 1e10, σ_1::Real = 1.0, M::Int = 10,
    γ::Real = 1e-4, τ_min::Real = 0.1, τ_max::Real = 0.5, n_exp::Int = 2,
    η_strategy::Function = (fn_1, n, x_n, f_n) -&gt; fn_1 / n^2,
    max_inner_iterations::Int = 100)</code></pre><p>A low-overhead and allocation-free implementation of the df-sane method for solving large-scale nonlinear systems of equations. For in depth information about all the parameters and the algorithm, see the paper [1].</p><p><strong>Keyword Arguments</strong></p><ul><li><code>σ_min</code>: the minimum value of the spectral coefficient <code>σₙ</code> which is related to the step size in the algorithm. Defaults to <code>1e-10</code>.</li><li><code>σ_max</code>: the maximum value of the spectral coefficient <code>σₙ</code> which is related to the step size in the algorithm. Defaults to <code>1e10</code>.</li><li><code>σ_1</code>: the initial value of the spectral coefficient <code>σₙ</code> which is related to the step size in the algorithm.. Defaults to <code>1.0</code>.</li><li><code>M</code>: The monotonicity of the algorithm is determined by a this positive integer. A value of 1 for <code>M</code> would result in strict monotonicity in the decrease of the L2-norm of the function <code>f</code>. However, higher values allow for more flexibility in this reduction. Despite this, the algorithm still ensures global convergence through the use of a non-monotone line-search algorithm that adheres to the Grippo-Lampariello-Lucidi condition. Values in the range of 5 to 20 are usually sufficient, but some cases may call for a higher value of <code>M</code>. The default setting is 10.</li><li><code>γ</code>: a parameter that influences if a proposed step will be accepted. Higher value of <code>γ</code> will make the algorithm more restrictive in accepting steps. Defaults to <code>1e-4</code>.</li><li><code>τ_min</code>: if a step is rejected the new step size will get multiplied by factor, and this parameter is the minimum value of that factor. Defaults to <code>0.1</code>.</li><li><code>τ_max</code>: if a step is rejected the new step size will get multiplied by factor, and this parameter is the maximum value of that factor. Defaults to <code>0.5</code>.</li><li><code>n_exp</code>: the exponent of the loss, i.e. <span>$f_n=||F(x_n)||^{n_exp}$</span>. The paper uses <code>n_exp ∈ {1,2}</code>. Defaults to <code>2</code>.</li><li><code>η_strategy</code>:  function to determine the parameter <code>η</code>, which enables growth of <span>$||f_n||^2$</span>. Called as <span>$η = η_strategy(fn_1, n, x_n, f_n)$</span> with <code>fn_1</code> initialized as <span>$fn_1=||f(x_1)||^{n_exp}$</span>, <code>n</code> is the iteration number, <code>x_n</code> is the current <code>x</code>-value and <code>f_n</code> the current residual. Should satisfy <span>$η &gt; 0$</span> and <span>$∑ₖ ηₖ &lt; ∞$</span>. Defaults to <span>$fn_1 / n^2$</span>.</li><li><code>max_inner_iterations</code>: the maximum number of iterations allowed for the inner loop of the algorithm. Defaults to <code>100</code>.</li></ul><p><strong>References</strong></p><p>[1] W LaCruz, JM Martinez, and M Raydan (2006), Spectral Residual Method without Gradient Information for Solving Large-Scale Nonlinear Systems of Equations, Mathematics of Computation, 75, 1429-1448.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/dfsane.jl#L1-L47">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.Broyden" href="#NonlinearSolve.Broyden"><code>NonlinearSolve.Broyden</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Broyden(; max_resets = 100, linesearch = nothing, reset_tolerance = nothing,
    init_jacobian::Val = Val(:identity), autodiff = nothing, alpha = nothing)</code></pre><p>An implementation of <code>Broyden</code> with resetting and line search.</p><p><strong>Arguments</strong></p><ul><li><p><code>max_resets</code>: the maximum number of resets to perform. Defaults to <code>100</code>.</p></li><li><p><code>reset_tolerance</code>: the tolerance for the reset check. Defaults to <code>sqrt(eps(real(eltype(u))))</code>.</p></li><li><p><code>linesearch</code>: the line search algorithm to use. Defaults to <a href="../../solvers/LineSearch/#NonlinearSolve.LineSearch"><code>LineSearch()</code></a>, which means that no line search is performed. Algorithms from <code>LineSearches.jl</code> can be used here directly, and they will be converted to the correct <code>LineSearch</code>. It is recommended to use <a href="../../solvers/LineSearch/#NonlinearSolve.LiFukushimaLineSearch"><code>LiFukushimaLineSearch</code></a> – a derivative free linesearch specifically designed for Broyden&#39;s method.</p></li><li><p><code>alpha</code>: If <code>init_jacobian</code> is set to <code>Val(:identity)</code>, then the initial Jacobian inverse is set to be <code>(αI)⁻¹</code>. Defaults to <code>nothing</code> which implies <code>α = max(norm(u), 1) / (2 * norm(fu))</code>.</p></li><li><p><code>init_jacobian</code>: the method to use for initializing the jacobian. Defaults to <code>Val(:identity)</code>. Choices include:</p><ul><li><code>Val(:identity)</code>: Identity Matrix.</li><li><code>Val(:true_jacobian)</code>: True Jacobian. This is a good choice for differentiable problems.</li></ul></li><li><p><code>autodiff</code>: determines the backend used for the Jacobian. Note that this argument is ignored if an analytical Jacobian is passed, as that will be used instead. Defaults to <code>nothing</code> which means that a default is selected according to the problem specification! Valid choices are types from ADTypes.jl. (Used if <code>init_jacobian = Val(:true_jacobian)</code>)</p></li><li><p><code>update_rule</code>: Update Rule for the Jacobian. Choices are:</p><ul><li><code>Val(:good_broyden)</code>: Good Broyden&#39;s Update Rule</li><li><code>Val(:bad_broyden)</code>: Bad Broyden&#39;s Update Rule</li><li><code>Val(:diagonal)</code>: Only update the diagonal of the Jacobian. This algorithm may be useful for specific problems, but whether it will work may depend strongly on the problem.</li></ul></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/broyden.jl#L2-L39">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.Klement" href="#NonlinearSolve.Klement"><code>NonlinearSolve.Klement</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Klement(; max_resets = 100, linsolve = nothing, linesearch = nothing,
    precs = DEFAULT_PRECS, alpha = true, init_jacobian::Val = Val(:identity),
    autodiff = nothing)</code></pre><p>An implementation of <code>Klement</code> with line search, preconditioning and customizable linear solves. It is recommended to use <code>Broyden</code> for most problems over this.</p><p><strong>Keyword Arguments</strong></p><ul><li><p><code>max_resets</code>: the maximum number of resets to perform. Defaults to <code>100</code>.</p></li><li><p><code>linsolve</code>: the <a href="https://github.com/SciML/LinearSolve.jl">LinearSolve.jl</a> used for the linear solves within the Newton method. Defaults to <code>nothing</code>, which means it uses the LinearSolve.jl default algorithm choice. For more information on available algorithm choices, see the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</p></li><li><p><code>precs</code>: the choice of preconditioners for the linear solver. Defaults to using no preconditioners. For more information on specifying preconditioners for LinearSolve algorithms, consult the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</p></li><li><p><code>linesearch</code>: the line search algorithm to use. Defaults to <a href="../../solvers/LineSearch/#NonlinearSolve.LineSearch"><code>LineSearch()</code></a>, which means that no line search is performed. Algorithms from <code>LineSearches.jl</code> can be used here directly, and they will be converted to the correct <code>LineSearch</code>.</p></li><li><p><code>alpha</code>: If <code>init_jacobian</code> is set to <code>Val(:identity)</code>, then the initial Jacobian inverse is set to be <code>αI</code>. Defaults to <code>1</code>. Can be set to <code>nothing</code> which implies <code>α = max(norm(u), 1) / (2 * norm(fu))</code>.</p></li><li><p><code>init_jacobian</code>: the method to use for initializing the jacobian. Defaults to <code>Val(:identity)</code>. Choices include:</p><ul><li><code>Val(:identity)</code>: Identity Matrix.</li><li><code>Val(:true_jacobian)</code>: True Jacobian. Our tests suggest that this is not very stable. Instead using <code>Broyden</code> with <code>Val(:true_jacobian)</code> gives faster and more reliable convergence.</li><li><code>Val(:true_jacobian_diagonal)</code>: Diagonal of True Jacobian. This is a good choice for differentiable problems.</li></ul></li><li><p><code>autodiff</code>: determines the backend used for the Jacobian. Note that this argument is ignored if an analytical Jacobian is passed, as that will be used instead. Defaults to <code>nothing</code> which means that a default is selected according to the problem specification! Valid choices are types from ADTypes.jl. (Used if <code>init_jacobian = Val(:true_jacobian)</code>)</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/klement.jl#L1-L40">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.LimitedMemoryBroyden" href="#NonlinearSolve.LimitedMemoryBroyden"><code>NonlinearSolve.LimitedMemoryBroyden</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LimitedMemoryBroyden(; max_resets::Int = 3, linesearch = nothing,
    threshold::Int = 10, reset_tolerance = nothing)</code></pre><p>An implementation of <code>LimitedMemoryBroyden</code> with resetting and line search.</p><p><strong>Arguments</strong></p><ul><li><code>max_resets</code>: the maximum number of resets to perform. Defaults to <code>3</code>.</li><li><code>reset_tolerance</code>: the tolerance for the reset check. Defaults to <code>sqrt(eps(real(eltype(u))))</code>.</li><li><code>threshold</code>: the number of vectors to store in the low rank approximation. Defaults to <code>10</code>.</li><li><code>linesearch</code>: the line search algorithm to use. Defaults to <a href="../../solvers/LineSearch/#NonlinearSolve.LineSearch"><code>LineSearch()</code></a>, which means that no line search is performed. Algorithms from <code>LineSearches.jl</code> can be used here directly, and they will be converted to the correct <code>LineSearch</code>. It is recommended to use <a href="../../solvers/LineSearch/#NonlinearSolve.LiFukushimaLineSearch"><code>LiFukushimaLineSearch</code></a> – a derivative free linesearch specifically designed for Broyden&#39;s method.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/lbroyden.jl#L1-L19">source</a></section></article><h2 id="Nonlinear-Least-Squares-Solvers"><a class="docs-heading-anchor" href="#Nonlinear-Least-Squares-Solvers">Nonlinear Least Squares Solvers</a><a id="Nonlinear-Least-Squares-Solvers-1"></a><a class="docs-heading-anchor-permalink" href="#Nonlinear-Least-Squares-Solvers" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.GaussNewton" href="#NonlinearSolve.GaussNewton"><code>NonlinearSolve.GaussNewton</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GaussNewton(; concrete_jac = nothing, linsolve = nothing, linesearch = nothing,
    precs = DEFAULT_PRECS, adkwargs...)</code></pre><p>An advanced GaussNewton implementation with support for efficient handling of sparse matrices via colored automatic differentiation and preconditioned linear solvers. Designed for large-scale and numerically-difficult nonlinear least squares problems.</p><p><strong>Keyword Arguments</strong></p><ul><li><code>autodiff</code>: determines the backend used for the Jacobian. Note that this argument is ignored if an analytical Jacobian is passed, as that will be used instead. Defaults to <code>nothing</code> which means that a default is selected according to the problem specification! Valid choices are types from ADTypes.jl.</li><li><code>concrete_jac</code>: whether to build a concrete Jacobian. If a Krylov-subspace method is used, then the Jacobian will not be constructed and instead direct Jacobian-vector products <code>J*v</code> are computed using forward-mode automatic differentiation or finite differencing tricks (without ever constructing the Jacobian). However, if the Jacobian is still needed, for example for a preconditioner, <code>concrete_jac = true</code> can be passed in order to force the construction of the Jacobian.</li><li><code>linsolve</code>: the <a href="https://github.com/SciML/LinearSolve.jl">LinearSolve.jl</a> used for the linear solves within the Newton method. Defaults to <code>nothing</code>, which means it uses the LinearSolve.jl default algorithm choice. For more information on available algorithm choices, see the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>precs</code>: the choice of preconditioners for the linear solver. Defaults to using no preconditioners. For more information on specifying preconditioners for LinearSolve algorithms, consult the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>linesearch</code>: the line search algorithm to use. Defaults to <a href="../../solvers/LineSearch/#NonlinearSolve.LineSearch"><code>LineSearch()</code></a>, which means that no line search is performed. Algorithms from <code>LineSearches.jl</code> can be used here directly, and they will be converted to the correct <code>LineSearch</code>.</li><li><code>vjp_autodiff</code>: Automatic Differentiation Backend used for vector-jacobian products. This is applicable if the linear solver doesn&#39;t require a concrete jacobian, for eg., Krylov Methods. Defaults to <code>nothing</code>, which means if the problem is out of place and <code>Zygote</code> is loaded then, we use <code>AutoZygote</code>. In all other, cases <code>FiniteDiff</code> is used.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/gaussnewton.jl#L1-L36">source</a></section></article><h2 id="Both-Nonlinear-and-Nonlinear-Least-Squares-Solvers"><a class="docs-heading-anchor" href="#Both-Nonlinear-and-Nonlinear-Least-Squares-Solvers">Both Nonlinear &amp; Nonlinear Least Squares Solvers</a><a id="Both-Nonlinear-and-Nonlinear-Least-Squares-Solvers-1"></a><a class="docs-heading-anchor-permalink" href="#Both-Nonlinear-and-Nonlinear-Least-Squares-Solvers" title="Permalink"></a></h2><p>These solvers can be used for both nonlinear and nonlinear least squares problems.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.TrustRegion" href="#NonlinearSolve.TrustRegion"><code>NonlinearSolve.TrustRegion</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TrustRegion(; concrete_jac = nothing, linsolve = nothing, precs = DEFAULT_PRECS,
    radius_update_scheme::RadiusUpdateSchemes.T = RadiusUpdateSchemes.Simple,
    max_trust_radius::Real = 0 // 1, initial_trust_radius::Real = 0 // 1,
    step_threshold::Real = 1 // 10, shrink_threshold::Real = 1 // 4,
    expand_threshold::Real = 3 // 4, shrink_factor::Real = 1 // 4,
    expand_factor::Real = 2 // 1, max_shrink_times::Int = 32, adkwargs...)</code></pre><p>An advanced TrustRegion implementation with support for efficient handling of sparse matrices via colored automatic differentiation and preconditioned linear solvers. Designed for large-scale and numerically-difficult nonlinear systems.</p><p><strong>Keyword Arguments</strong></p><ul><li><code>autodiff</code>: determines the backend used for the Jacobian. Note that this argument is ignored if an analytical Jacobian is passed, as that will be used instead. Defaults to <code>nothing</code> which means that a default is selected according to the problem specification!. Valid choices are types from ADTypes.jl.</li><li><code>concrete_jac</code>: whether to build a concrete Jacobian. If a Krylov-subspace method is used, then the Jacobian will not be constructed and instead direct Jacobian-vector products <code>J*v</code> are computed using forward-mode automatic differentiation or finite differencing tricks (without ever constructing the Jacobian). However, if the Jacobian is still needed, for example for a preconditioner, <code>concrete_jac = true</code> can be passed in order to force the construction of the Jacobian.</li><li><code>linsolve</code>: the <a href="https://github.com/SciML/LinearSolve.jl">LinearSolve.jl</a> used for the linear solves within the Newton method. Defaults to <code>nothing</code>, which means it uses the LinearSolve.jl default algorithm choice. For more information on available algorithm choices, see the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>precs</code>: the choice of preconditioners for the linear solver. Defaults to using no preconditioners. For more information on specifying preconditioners for LinearSolve algorithms, consult the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>radius_update_scheme</code>: the choice of radius update scheme to be used. Defaults to <code>RadiusUpdateSchemes.Simple</code> which follows the conventional approach. Other available schemes are <code>RadiusUpdateSchemes.Hei</code>, <code>RadiusUpdateSchemes.Yuan</code>, <code>RadiusUpdateSchemes.Bastin</code>, <code>RadiusUpdateSchemes.Fan</code>. These schemes have the trust region radius converging to zero that is seen to improve convergence. For more details, see the <a href="https://link.springer.com/article/10.1007/s10107-015-0893-2#Sec4">Yuan, Yx</a>.</li><li><code>max_trust_radius</code>: the maximal trust region radius. Defaults to <code>max(norm(fu), maximum(u) - minimum(u))</code>.</li><li><code>initial_trust_radius</code>: the initial trust region radius. Defaults to <code>max_trust_radius / 11</code>.</li><li><code>step_threshold</code>: the threshold for taking a step. In every iteration, the threshold is compared with a value <code>r</code>, which is the actual reduction in the objective function divided by the predicted reduction. If <code>step_threshold &gt; r</code> the model is not a good approximation, and the step is rejected. Defaults to <code>0.1</code>. For more details, see <a href="https://link.springer.com/article/10.1007/s40096-020-00339-4">Rahpeymaii, F.</a></li><li><code>shrink_threshold</code>: the threshold for shrinking the trust region radius. In every iteration, the threshold is compared with a value <code>r</code> which is the actual reduction in the objective function divided by the predicted reduction. If <code>shrink_threshold &gt; r</code> the trust region radius is shrunk by <code>shrink_factor</code>. Defaults to <code>0.25</code>. For more details, see <a href="https://link.springer.com/article/10.1007/s40096-020-00339-4">Rahpeymaii, F.</a></li><li><code>expand_threshold</code>: the threshold for expanding the trust region radius. If a step is taken, i.e <code>step_threshold &lt; r</code> (with <code>r</code> defined in <code>shrink_threshold</code>), a check is also made to see if <code>expand_threshold &lt; r</code>. If that is true, the trust region radius is expanded by <code>expand_factor</code>. Defaults to <code>0.75</code>.</li><li><code>shrink_factor</code>: the factor to shrink the trust region radius with if <code>shrink_threshold &gt; r</code> (with <code>r</code> defined in <code>shrink_threshold</code>). Defaults to <code>0.25</code>.</li><li><code>expand_factor</code>: the factor to expand the trust region radius with if <code>expand_threshold &lt; r</code> (with <code>r</code> defined in <code>shrink_threshold</code>). Defaults to <code>2.0</code>.</li><li><code>max_shrink_times</code>: the maximum number of times to shrink the trust region radius in a row, <code>max_shrink_times</code> is exceeded, the algorithm returns. Defaults to <code>32</code>.</li><li><code>vjp_autodiff</code>: Automatic Differentiation Backend used for vector-jacobian products. This is applicable if the linear solver doesn&#39;t require a concrete jacobian, for eg., Krylov Methods. Defaults to <code>nothing</code>, which means if the problem is out of place and <code>Zygote</code> is loaded then, we use <code>AutoZygote</code>. In all other, cases <code>FiniteDiff</code> is used.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/trustRegion.jl#L102-L167">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.LevenbergMarquardt" href="#NonlinearSolve.LevenbergMarquardt"><code>NonlinearSolve.LevenbergMarquardt</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LevenbergMarquardt(; concrete_jac = nothing, linsolve = nothing,
    precs = DEFAULT_PRECS, damping_initial::Real = 1.0,
    damping_increase_factor::Real = 2.0, damping_decrease_factor::Real = 3.0,
    finite_diff_step_geodesic::Real = 0.1, α_geodesic::Real = 0.75,
    b_uphill::Real = 1.0, min_damping_D::AbstractFloat = 1e-8, adkwargs...)</code></pre><p>An advanced Levenberg-Marquardt implementation with the improvements suggested in the <a href="https://arxiv.org/abs/1201.5885">paper</a> &quot;Improvements to the Levenberg-Marquardt algorithm for nonlinear least-squares minimization&quot;. Designed for large-scale and numerically-difficult nonlinear systems.</p><p><strong>How to Choose the Linear Solver?</strong></p><p>There are 2 ways to perform the LM Step</p><ol><li>Solve <code>(JᵀJ + λDᵀD) δx = Jᵀf</code> directly using a linear solver</li><li>Solve for <code>Jδx = f</code> and <code>√λ⋅D δx = 0</code> simultaneously (to derive this simply compute the normal form for this)</li></ol><p>The second form tends to be more robust and can be solved using any Least Squares Solver. If no <code>linsolve</code> or a least squares solver is provided, then we will solve the 2nd form. However, in most cases, this means losing structure in <code>J</code> which is not ideal. Note that whatever you do, do not specify solvers like <code>linsolve = NormalCholeskyFactorization()</code> or any such solver which converts the equation to normal form before solving. These don&#39;t use cache efficiently and we already support the normal form natively.</p><p>Additionally, note that the first form leads to a positive definite system, so we can use more efficient solvers like <code>linsolve = CholeskyFactorization()</code>. If you know that the problem is very well conditioned, then you might want to solve the normal form directly.</p><p><strong>Keyword Arguments</strong></p><ul><li><code>autodiff</code>: determines the backend used for the Jacobian. Note that this argument is ignored if an analytical Jacobian is passed, as that will be used instead. Defaults to <code>nothing</code> which means that a default is selected according to the problem specification! Valid choices are types from ADTypes.jl.</li><li><code>concrete_jac</code>: whether to build a concrete Jacobian. If a Krylov-subspace method is used, then the Jacobian will not be constructed and instead direct Jacobian-vector products <code>J*v</code> are computed using forward-mode automatic differentiation or finite differencing tricks (without ever constructing the Jacobian). However, if the Jacobian is still needed, for example for a preconditioner, <code>concrete_jac = true</code> can be passed in order to force the construction of the Jacobian.</li><li><code>linsolve</code>: the <a href="https://github.com/SciML/LinearSolve.jl">LinearSolve.jl</a> used for the linear solves within the Newton method. Defaults to <code>nothing</code>, which means it uses the LinearSolve.jl default algorithm choice. For more information on available algorithm choices, see the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>precs</code>: the choice of preconditioners for the linear solver. Defaults to using no preconditioners. For more information on specifying preconditioners for LinearSolve algorithms, consult the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>damping_initial</code>: the starting value for the damping factor. The damping factor is inversely proportional to the step size. The damping factor is adjusted during each iteration. Defaults to <code>1.0</code>. For more details, see section 2.1 of <a href="https://arxiv.org/abs/1201.5885">this paper</a>.</li><li><code>damping_increase_factor</code>: the factor by which the damping is increased if a step is rejected. Defaults to <code>2.0</code>. For more details, see section 2.1 of <a href="https://arxiv.org/abs/1201.5885">this paper</a>.</li><li><code>damping_decrease_factor</code>: the factor by which the damping is decreased if a step is accepted. Defaults to <code>3.0</code>. For more details, see section 2.1 of <a href="https://arxiv.org/abs/1201.5885">this paper</a>.</li><li><code>finite_diff_step_geodesic</code>: the step size used for finite differencing used to calculate the geodesic acceleration. Defaults to <code>0.1</code> which means that the step size is approximately 10% of the first-order step. For more details, see section 3 of <a href="https://arxiv.org/abs/1201.5885">this paper</a>.</li><li><code>α_geodesic</code>: a factor that determines if a step is accepted or rejected. To incorporate geodesic acceleration as an addition to the Levenberg-Marquardt algorithm, it is necessary that acceptable steps meet the condition <span>$\frac{2||a||}{||v||} \le \alpha_{\text{geodesic}}$</span>, where <span>$a$</span> is the geodesic acceleration, <span>$v$</span> is the Levenberg-Marquardt algorithm&#39;s step (velocity along a geodesic path) and <code>α_geodesic</code> is some number of order <code>1</code>. For most problems <code>α_geodesic = 0.75</code> is a good value but for problems where convergence is difficult <code>α_geodesic = 0.1</code> is an effective choice. Defaults to <code>0.75</code>. For more details, see section 3, equation (15) of <a href="https://arxiv.org/abs/1201.5885">this paper</a>.</li><li><code>b_uphill</code>: a factor that determines if a step is accepted or rejected. The standard choice in the Levenberg-Marquardt method is to accept all steps that decrease the cost and reject all steps that increase the cost. Although this is a natural and safe choice, it is often not the most efficient. Therefore downhill moves are always accepted, but uphill moves are only conditionally accepted. To decide whether an uphill move will be accepted at each iteration <span>$i$</span>, we compute <span>$\beta_i = \cos(v_{\text{new}}, v_{\text{old}})$</span>, which denotes the cosine angle between the proposed velocity <span>$v_{\text{new}}$</span> and the velocity of the last accepted step <span>$v_{\text{old}}$</span>. The idea is to accept uphill moves if the angle is small. To specify, uphill moves are accepted if <span>$(1-\beta_i)^{b_{\text{uphill}}} C_{i+1} \le C_i$</span>, where <span>$C_i$</span> is the cost at iteration <span>$i$</span>. Reasonable choices for <code>b_uphill</code> are <code>1.0</code> or <code>2.0</code>, with <code>b_uphill=2.0</code> allowing higher uphill moves than <code>b_uphill=1.0</code>. When <code>b_uphill=0.0</code>, no uphill moves will be accepted. Defaults to <code>1.0</code>. For more details, see section 4 of <a href="https://arxiv.org/abs/1201.5885">this paper</a>.</li><li><code>min_damping_D</code>: the minimum value of the damping terms in the diagonal damping matrix <code>DᵀD</code>, where <code>DᵀD</code> is given by the largest diagonal entries of <code>JᵀJ</code> yet encountered, where <code>J</code> is the Jacobian. It is suggested by <a href="https://arxiv.org/abs/1201.5885">this paper</a> to use a minimum value of the elements in <code>DᵀD</code> to prevent the damping from being too small. Defaults to <code>1e-8</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/levenberg.jl#L1-L95">source</a></section></article><h2 id="Polyalgorithms"><a class="docs-heading-anchor" href="#Polyalgorithms">Polyalgorithms</a><a id="Polyalgorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Polyalgorithms" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.NonlinearSolvePolyAlgorithm" href="#NonlinearSolve.NonlinearSolvePolyAlgorithm"><code>NonlinearSolve.NonlinearSolvePolyAlgorithm</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NonlinearSolvePolyAlgorithm(algs, ::Val{pType} = Val(:NLS)) where {pType}</code></pre><p>A general way to define PolyAlgorithms for <code>NonlinearProblem</code> and <code>NonlinearLeastSquaresProblem</code>. This is a container for a tuple of algorithms that will be tried in order until one succeeds. If none succeed, then the algorithm with the lowest residual is returned.</p><p><strong>Arguments</strong></p><ul><li><code>algs</code>: a tuple of algorithms to try in-order! (If this is not a Tuple, then the returned algorithm is not type-stable).</li><li><code>pType</code>: the problem type. Defaults to <code>:NLS</code> for <code>NonlinearProblem</code> and <code>:NLLS</code> for <code>NonlinearLeastSquaresProblem</code>. This is used to determine the correct problem type to dispatch on.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">using NonlinearSolve

alg = NonlinearSolvePolyAlgorithm((NewtonRaphson(), Broyden()))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/default.jl#L1-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.FastShortcutNonlinearPolyalg" href="#NonlinearSolve.FastShortcutNonlinearPolyalg"><code>NonlinearSolve.FastShortcutNonlinearPolyalg</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">FastShortcutNonlinearPolyalg(::Type{T} = Float64; concrete_jac = nothing,
    linsolve = nothing, precs = DEFAULT_PRECS, must_use_jacobian::Val = Val(false),
    prefer_simplenonlinearsolve::Val{SA} = Val(false), autodiff = nothing) where {T}</code></pre><p>A polyalgorithm focused on balancing speed and robustness. It first tries less robust methods for more performance and then tries more robust techniques if the faster ones fail.</p><p><strong>Arguments</strong></p><ul><li><code>T</code>: The eltype of the initial guess. It is only used to check if some of the algorithms are compatible with the problem type. Defaults to <code>Float64</code>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>autodiff</code>: determines the backend used for the Jacobian. Note that this argument is ignored if an analytical Jacobian is passed, as that will be used instead. Defaults to <code>nothing</code>.</li><li><code>concrete_jac</code>: whether to build a concrete Jacobian. If a Krylov-subspace method is used, then the Jacobian will not be constructed and instead direct Jacobian-vector products <code>J*v</code> are computed using forward-mode automatic differentiation or finite differencing tricks (without ever constructing the Jacobian). However, if the Jacobian is still needed, for example for a preconditioner, <code>concrete_jac = true</code> can be passed in order to force the construction of the Jacobian.</li><li><code>linsolve</code>: the <a href="https://github.com/SciML/LinearSolve.jl">LinearSolve.jl</a> used for the linear solves within the Newton method. Defaults to <code>nothing</code>, which means it uses the LinearSolve.jl default algorithm choice. For more information on available algorithm choices, see the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>precs</code>: the choice of preconditioners for the linear solver. Defaults to using no preconditioners. For more information on specifying preconditioners for LinearSolve algorithms, consult the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/default.jl#L223-L255">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.FastShortcutNLLSPolyalg" href="#NonlinearSolve.FastShortcutNLLSPolyalg"><code>NonlinearSolve.FastShortcutNLLSPolyalg</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">FastShortcutNLLSPolyalg(::Type{T} = Float64; concrete_jac = nothing, linsolve = nothing,
    precs = DEFAULT_PRECS, kwargs...)</code></pre><p>A polyalgorithm focused on balancing speed and robustness. It first tries less robust methods for more performance and then tries more robust techniques if the faster ones fail.</p><p><strong>Arguments</strong></p><ul><li><code>T</code>: The eltype of the initial guess. It is only used to check if some of the algorithms are compatible with the problem type. Defaults to <code>Float64</code>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>autodiff</code>: determines the backend used for the Jacobian. Note that this argument is ignored if an analytical Jacobian is passed, as that will be used instead. Defaults to <code>AutoForwardDiff()</code>. Valid choices are types from ADTypes.jl.</li><li><code>concrete_jac</code>: whether to build a concrete Jacobian. If a Krylov-subspace method is used, then the Jacobian will not be constructed and instead direct Jacobian-vector products <code>J*v</code> are computed using forward-mode automatic differentiation or finite differencing tricks (without ever constructing the Jacobian). However, if the Jacobian is still needed, for example for a preconditioner, <code>concrete_jac = true</code> can be passed in order to force the construction of the Jacobian.</li><li><code>linsolve</code>: the <a href="https://github.com/SciML/LinearSolve.jl">LinearSolve.jl</a> used for the linear solves within the Newton method. Defaults to <code>nothing</code>, which means it uses the LinearSolve.jl default algorithm choice. For more information on available algorithm choices, see the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>precs</code>: the choice of preconditioners for the linear solver. Defaults to using no preconditioners. For more information on specifying preconditioners for LinearSolve algorithms, consult the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/default.jl#L314-L345">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.RobustMultiNewton" href="#NonlinearSolve.RobustMultiNewton"><code>NonlinearSolve.RobustMultiNewton</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">RobustMultiNewton(::Type{T} = Float64; concrete_jac = nothing, linsolve = nothing,
    precs = DEFAULT_PRECS, autodiff = nothing)</code></pre><p>A polyalgorithm focused on robustness. It uses a mixture of Newton methods with different globalizing techniques (trust region updates, line searches, etc.) in order to find a method that is able to adequately solve the minimization problem.</p><p>Basically, if this algorithm fails, then &quot;most&quot; good ways of solving your problem fail and you may need to think about reformulating the model (either there is an issue with the model, or more precision / more stable linear solver choice is required).</p><p><strong>Arguments</strong></p><ul><li><code>T</code>: The eltype of the initial guess. It is only used to check if some of the algorithms are compatible with the problem type. Defaults to <code>Float64</code>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>autodiff</code>: determines the backend used for the Jacobian. Note that this argument is ignored if an analytical Jacobian is passed, as that will be used instead. Defaults to <code>nothing</code>.</li><li><code>concrete_jac</code>: whether to build a concrete Jacobian. If a Krylov-subspace method is used, then the Jacobian will not be constructed and instead direct Jacobian-vector products <code>J*v</code> are computed using forward-mode automatic differentiation or finite differencing tricks (without ever constructing the Jacobian). However, if the Jacobian is still needed, for example for a preconditioner, <code>concrete_jac = true</code> can be passed in order to force the construction of the Jacobian.</li><li><code>linsolve</code>: the <a href="https://github.com/SciML/LinearSolve.jl">LinearSolve.jl</a> used for the linear solves within the Newton method. Defaults to <code>nothing</code>, which means it uses the LinearSolve.jl default algorithm choice. For more information on available algorithm choices, see the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li><li><code>precs</code>: the choice of preconditioners for the linear solver. Defaults to using no preconditioners. For more information on specifying preconditioners for LinearSolve algorithms, consult the <a href="https://docs.sciml.ai/LinearSolve/stable/">LinearSolve.jl documentation</a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/default.jl#L167-L203">source</a></section></article><h2 id="Radius-Update-Schemes-for-Trust-Region-(RadiusUpdateSchemes)"><a class="docs-heading-anchor" href="#Radius-Update-Schemes-for-Trust-Region-(RadiusUpdateSchemes)">Radius Update Schemes for Trust Region (RadiusUpdateSchemes)</a><a id="Radius-Update-Schemes-for-Trust-Region-(RadiusUpdateSchemes)-1"></a><a class="docs-heading-anchor-permalink" href="#Radius-Update-Schemes-for-Trust-Region-(RadiusUpdateSchemes)" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.RadiusUpdateSchemes" href="#NonlinearSolve.RadiusUpdateSchemes"><code>NonlinearSolve.RadiusUpdateSchemes</code></a> — <span class="docstring-category">Module</span></header><section><div><pre><code class="language-julia hljs">RadiusUpdateSchemes</code></pre><p><code>RadiusUpdateSchemes</code> is the standard enum interface for different types of radius update schemes implemented in the Trust Region method. These schemes specify how the radius of the so-called trust region is updated after each iteration of the algorithm. The specific role and caveats associated with each scheme are provided below.</p><p><strong>Using <code>RadiusUpdateSchemes</code></strong></p><p><code>RadiusUpdateSchemes</code> uses the standard <a href="https://github.com/fredrikekre/EnumX.jl">EnumX Interface</a>, and hence inherits all properties of being an EnumX, including the type of each constituent enum states as <code>RadiusUpdateSchemes.T</code>. Simply put the desired scheme as follows: <code>TrustRegion(radius_update_scheme = your desired update scheme)</code>. For example, <code>sol = solve(prob, alg=TrustRegion(radius_update_scheme = RadiusUpdateSchemes.Hei))</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/trustRegion.jl#L1-L17">source</a></section></article><h3 id="Available-Radius-Update-Schemes"><a class="docs-heading-anchor" href="#Available-Radius-Update-Schemes">Available Radius Update Schemes</a><a id="Available-Radius-Update-Schemes-1"></a><a class="docs-heading-anchor-permalink" href="#Available-Radius-Update-Schemes" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.RadiusUpdateSchemes.Simple" href="#NonlinearSolve.RadiusUpdateSchemes.Simple"><code>NonlinearSolve.RadiusUpdateSchemes.Simple</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia hljs">RadiusUpdateSchemes.Simple</code></pre><p>The simple or conventional radius update scheme. This scheme is chosen by default and follows the conventional approach to update the trust region radius, i.e. if the trial step is accepted it increases the radius by a fixed factor (bounded by a maximum radius) and if the trial step is rejected, it shrinks the radius by a fixed factor.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/trustRegion.jl#L19-L26">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.RadiusUpdateSchemes.Hei" href="#NonlinearSolve.RadiusUpdateSchemes.Hei"><code>NonlinearSolve.RadiusUpdateSchemes.Hei</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia hljs">RadiusUpdateSchemes.Hei</code></pre><p>This scheme is proposed by Hei, L. [1]. The trust region radius depends on the size (norm) of the current step size. The hypothesis is to let the radius converge to zero as the iterations progress, which is more reliable and robust for ill-conditioned as well as degenerate problems.</p><p>[1] Hei, Long. &quot;A self-adaptive trust region algorithm.&quot; Journal of Computational Mathematics (2003): 229-236.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/trustRegion.jl#L44-L54">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.RadiusUpdateSchemes.Yuan" href="#NonlinearSolve.RadiusUpdateSchemes.Yuan"><code>NonlinearSolve.RadiusUpdateSchemes.Yuan</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia hljs">RadiusUpdateSchemes.Yuan</code></pre><p>This scheme is proposed by Yuan, Y [1]. Similar to Hei&#39;s scheme, the trust region is updated in a way so that it converges to zero, however here, the radius depends on the size (norm) of the current gradient of the objective (merit) function. The hypothesis is that the step size is bounded by the gradient size, so it makes sense to let the radius depend on the gradient.</p><p>[1] Fan, Jinyan, Jianyu Pan, and Hongyan Song. &quot;A retrospective trust region algorithm with trust region converging to zero.&quot; Journal of Computational Mathematics 34.4 (2016): 421-436.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/trustRegion.jl#L57-L69">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.RadiusUpdateSchemes.Bastin" href="#NonlinearSolve.RadiusUpdateSchemes.Bastin"><code>NonlinearSolve.RadiusUpdateSchemes.Bastin</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia hljs">RadiusUpdateSchemes.Bastin</code></pre><p>This scheme is proposed by Bastin, et al. [1]. The scheme is called a retrospective update scheme as it uses the model function at the current iteration to compute the ratio of the actual reduction and the predicted reduction in the previous trial step, and use this ratio to update the trust region radius. The hypothesis is to exploit the information made available during the optimization process in order to vary the accuracy of the objective function computation.</p><p>[1] Bastin, Fabian, et al. &quot;A retrospective trust-region method for unconstrained optimization.&quot; Mathematical programming 123 (2010): 395-418.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/trustRegion.jl#L72-L84">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.RadiusUpdateSchemes.Fan" href="#NonlinearSolve.RadiusUpdateSchemes.Fan"><code>NonlinearSolve.RadiusUpdateSchemes.Fan</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia hljs">RadiusUpdateSchemes.Fan</code></pre><p>This scheme is proposed by Fan, J. [1]. It is very much similar to Hei&#39;s and Yuan&#39;s schemes as it lets the trust region radius depend on the current size (norm) of the objective (merit) function itself. These new update schemes are known to improve local convergence.</p><p>[1] Fan, Jinyan. &quot;Convergence rate of the trust region method for nonlinear equations under local error bound condition.&quot; Computational Optimization and Applications 34.2 (2006): 215-227.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/trustRegion.jl#L87-L98">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.RadiusUpdateSchemes.NLsolve" href="#NonlinearSolve.RadiusUpdateSchemes.NLsolve"><code>NonlinearSolve.RadiusUpdateSchemes.NLsolve</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia hljs">RadiusUpdateSchemes.NLsolve</code></pre><p>The same updating scheme as in NLsolve&#39;s (https://github.com/JuliaNLSolvers/NLsolve.jl) trust region dogleg implementation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/trustRegion.jl#L29-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="NonlinearSolve.RadiusUpdateSchemes.NocedalWright" href="#NonlinearSolve.RadiusUpdateSchemes.NocedalWright"><code>NonlinearSolve.RadiusUpdateSchemes.NocedalWright</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia hljs">RadiusUpdateSchemes.NocedalWright</code></pre><p>Trust region updating scheme as in Nocedal and Wright [see Alg 11.5, page 291].</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/NonlinearSolve.jl/blob/e65817b3de5691f4be9a13868204bcbe84525beb/src/trustRegion.jl#L37-L41">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../solvers/LineSearch/">« Line Search</a><a class="docs-footer-nextpage" href="../simplenonlinearsolve/">SimpleNonlinearSolve.jl »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Sunday 24 December 2023 20:12">Sunday 24 December 2023</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
